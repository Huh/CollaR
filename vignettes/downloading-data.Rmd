---
title: "Downloading Data"
author: "Josh Nowak"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Downloading Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Purpose

Data collected by tags attached to animals often relay data to users via satellite modems and email. Email is a cumbersome way to receive large amounts of data. For this reason manufacturers typically create a graphical user interface (GUI), which requires the user to visit a website, click on a series of buttons and download individual files. This workflow is better than email, but onerous if more than a few collars are deployed at a time. A more ideal workflow would be for a server to wake up in the middle of the night contact another server and download data in an automated fashion. Few companies, namely Vectronics, have developed application program interfaces (i.e. API) to solve this problem and facilitate the latter more desirable workflow. This package is a workaround for those using tags from companies that do not supply an API and in the case of Vectronics we offer a simple solution to interacting with the API via R. Writing this package in R (and using S3) is important because of the prevalance of R in wildlife science.  

### Roadmap

When creating this package we imagined a simple interface that made it easy for users to retrieve their data, but we realize that this is only the beginning and are working to create a series of tools for the standardization of data, visualization and analysis of telemetry derived locations. For more information on where we are headed or to give us your two cents visit the GitHub repository for the project at https://github.com/Huh/collar.

### Companies

At the time of this writing we have tools to download data from Vectronics, ATS, and legacy csv files. We have plans to work on Telonics in the near future and note that an option exists for Lotek via the [CollarScraper](https://github.com/rgzn/CollarScraper) package.

#### Vectronics

The Vectronics API is [documented here](https://www.vectronic-aerospace.com/wildlife-monitoring/vectronic-aerospace-http-wildlife-api/). A basic request to API is just a URL like www.google.com except that it also specifies some parameters, which tell the receiving server to do something.  Let's take a look

`https://wombat.vectronic-wildlife.com:9443/v2/collar/{collarid}/{datatype}?collarkey={key}`

Looking at the request we see that we are going to securely pass data via the encrypted https protocol. Then we see the base url for the server and it specifies port 9443. After that v2/collar/ and we don't need to know much about this chunk as we suspect it is for internal routing. Finally we get to some information that we are required to provide, the collar id. A collar id often looks like 1000001. After passing the collar id we will need to provide the datatype we want to retrieve. Data types depend on the device type, but generally include the following:

1) activity data
2) mortality implant data
3) mortality data
4) proximity data
5) position data
6) separation data
7) trap event data
8) vaginal implant data

The last piece of information we are required to pass is the collar key. A key is a bit of XML (eXtensible Markup Language) that allows Vectronics to identify each unique device and return the relevant data. Thankfully Vectronics provides a test key that we can all use to test the API. If you have your own keys that you want to use go for it, but for this example we provide instructions to build a test key. Let's begin by creating a key from scratch and then downloading the data for that device.

Building the key file is purely to make the example reproducible and if you have trouble there is a key file stored in the package, which can be located via the following command:
```{r eval = F}
system.file("extdata", "Collar123456_Registration.keyx", package = "collar")
```
The XML we will use to build our collar key is shown below:

```{r eval = F, echo = T}
<?xml version="1.0" encoding="utf-8"?>
<collarKey>
	<collar ID="1000001">
		<comIDList>
			<comID comType="Iridium">3004456789456</comID>
		</comIDList>
		<key>6484B8CA88E2B996421AB903D0B215AFAE285CAAE932F35F448154398398CF33AC40D37D9E37CEEA9DFCBD89353C3CCF8628A4DB4523F2324A83ADA5D091FB396DAC72773ED8CE1571D5C254FABBA0FBDEE2E1883694B8D18148168B205ED5BFA96ACEC30B7B99E045B8AE145B2A83948BAECD54CAB80A7676360B74CD1DEF7DDB50293E36B1C900EA853E19F808F745D85610F68609F233E294FA1C84700A80F1C257E062CAF4B2467E518A010A59E636091BAB905E50ED300BADF9F90440F7B85BBE14DD864BBB2F77A0A50BE5E14623D1B8FB0C2A3069207F4BFBF6CFEBC152F072D27B3CE88F844ED0197A56AF5114DE7B3BA544DB880850507FEB046684</key>
		<collarType>300</collarType>
	</collar>
</collarKey>
```

The XML may look intimidating, but it is just a few pieces of critical information stored in a rather standardized fashion. You will likely never need to interact with it directly. Now to create a key, open a text editor (e.g. Notepad, Notepad++, RStudio) and copy the XML into a blank text document. If you use RStudio be sure to open a new text document. Now name your text file "Collar1000001_Registration.keyx" and save it. I saved mine to "C:/Temp/vec_keys/Collar1000001_Registration.keyx", for reference.

We are now ready to download data from the test collar. Recall that my key is saved in "C:/Temp/vec_keys", so this is the value I want to pass to the `key_dir` argument of the `fetch_vectronics` function.

Load the package

```{r}
library(collar)
```

Call the API
```{r eval = F, warning = FALSE}
 vec_dat <- fetch_vectronics(key_dir = "C:/Temp/vec_keys")
```

Cool, but what just happened? Let's break down the function call into its pieces. First, I told you that the API required a collar id, a collar key and a data type, but in our call we only supplied a key directory. The collar package extracted the collar id from the collar key, then it extracted the long alphanumeric key from the key file and finally it guessed that you wanted GPS location data because no value was supplied. Using these pieces of information the fetch_* function builds a URL and calls the API. The function can handle many keys at once or a single key if desired. The function returns a [tibble](https://tibble.tidyverse.org/), which prints nicely to the screen and does not coerce or recycle values in an unreasonable way.

##### Data ID Limits

More advanced calls to the API can be made to only download subsets of the data. For example, we could assume the 600th value of idPosition came from the last download we performed. Imagine that last time we downloaded data this was the last value we received, we can pass this value to the `fetch_vectronics` function to limit the download to only new data not previously downloaded. *Note: Some users have reported odd behavior if positions were collected, but not transmitted it is possible that smaller/older values of idPosition were previously missed. Don't assume that you downloaded every point ever collected.*

```{r eval = F, warning = F}
new_dat <- fetch_vectronics(
  key_dir = "C:/Temp/vec_keys",
  after_data_id = vec_dat$idPosition[600]
)
```
##### Date Limits

Similarly, we can use dates to limit data downloads. The format of the date must be `YYYY-MM-DDTHH:MM:SS` and yes, the T is necessary. The scenario is the same, imagine we download data regularly, say daily, and we only want to download data with a scts date greater than some value. Below we create a date to use for downloading by subtracting 10 from the maximum observed date in the `vec_dat` created by the first download.

Create the date object used to subset the download
```{r eval = F}
after <- format(max(as.Date(vec_dat$scts)) - 10, "%Y-%m-%dT%H:%M:%S")
```

Call the API with the start date
```{r eval = F, warning = F}
after_dat <- fetch_vectronics(
  key_dir = "C:/Temp/vec_keys",
  start_date = after,
  which_date = "scts"
)
```
The same could be accomplished with the acquisition date by changing the call to
```{r eval = F, echo = T}
after_dat <- fetch_vectronics(
  key_dir = "C:/Temp/vec_keys",
  start_date = after,
  which_date = "acquistion"
)
```

If you have more than one collar to download then the length of the dates passed to `start_date` must be equal to the number of keys found in the key directory.  In other words, you have to have one date for each tag.

##### Data Types

Users can choose to download data of different types using they type argument. The possible options are:

1) `gps` - GPS location/position data
2) `act` - Activity data
3) `mit` - Implant mortality data
4) `mor` - Mortality data
5) `prx` - Proximity data
6) `SEP` - Separation data
7) `TRAP`- Trap event data

Definitions of the data types can be found in the [API documentation](https://www.vectronic-aerospace.com/wildlife-monitoring/vectronic-aerospace-http-wildlife-api/). So far, the calls above have implicitly called the API requesting GPS data, but what if we want activity data? A simple change to the `fetch_vectronics` call accomplishes this task.

```{r eval = F, warning = F}
act_dat <- fetch_vectronics(
  key_dir = "C:/Temp/vec_keys",
  type = "act"
)
```

The pattern is the same for the remaining data types.

***

#### ATS

ATS has a typical web portal that, like many companies, requires the user to click endless buttons in order to download data in a reasonable fashion. For this reason, the collar package provides web scraping utilities to interact with the ATS website. Webscraping is a technique that mimics user interactions with a website in order to make something happen, like retrieiving data. Have you ever seen a table of data on a website and thought I would like to have a copy of that? That is the job of webscraping, but in the case of the ATS site we are going to click buttons to get the desired data. Functionality at this point is somewhat limited, but also general, so if you choose to learn how to use the functions then you should be able to accomplish complex tasks.

The main function users interact with to download data from ATS is the `fetch_ats` function. This function has 4 arguments. The bttn_nm argument allows the user to control which data is downloaded by specifying the button to "click". The usr and pwd arguments are for authentication. Each user must provide there own credentials for authentication. The base_url argument has a default value of `atsidaq.net`, which should suffice for most all applications. If you navigate to `atsidaq.net` and login you will see the GUI and all of its buttons. Let's start with an example of downloading all the data from a study. 

```{r eval = F}
ats_dat <- fetch_ats(usr = Sys.getenv("ats_usr"), pwd = Sys.getenv("ats_pwd"))
```

In the above call we are downloading all data from all collars with data stored on the site. The only arguments we have to pass are the username and password. Here I have chosen to store the username and password as environmental variables. To read more about how to do this try [this link](https://cran.r-project.org/web/packages/httr/vignettes/secrets.html). So if all you ever want to do is download all the data and rely on a database to deal with [CRUD](https://en.wikipedia.org/wiki/Create,_read,_update_and_delete) like operations then you are done with the tutorial, but the function can do more. What if you wanted to download all the data passed by the button labelled "Download New Transmissions"? Well we need to pass the name of that button to the function and then we will get that data, but what do we mean by name? When you look at the button in the website you see that it has words on it, but those words are not the name or unique identifying bit of information. What we really need is stored in the HTML that makes up the webpage. My preferred way to get that information in Google Chrome is to right click and choose inspect. This gives me access to the developer tools and consequently the HTML for the site. Another great technique is to use [SelectorGadget](https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html). I won't go into great detail here, but will instead show examples of downloading data using different buttons.

Download data using new transmissions button
```{r eval = F}
new_trans <- fetch_ats(
  bttn_nm = "ctl00$ContentPlaceHolder1$DownloadAll2",
  usr = Sys.getenv("ats_usr"), 
  pwd = Sys.getenv("ats_pwd")
)
```

Download data using Download All Events button

*Note: At the time of this writing ATS was having a server issue and this request returned a 500 error code meaning an internal server error had occurred.*

```{r eval = F}
all_events <- fetch_ats(
  bttn_nm = "ctl00$ContentPlaceHolder1$DownLoadlastEvents",
  usr = Sys.getenv("ats_usr"), 
  pwd = Sys.getenv("ats_pwd")
)
```

Hopefully the pattern is clear, find the button name in the html and insert it into the bttn_nm argument of the function. This pattern applies to all buttons on the page that return data. A few buttons and their names are provided below for reference:

1) Download New Data - `ctl00$ContentPlaceHolder1$DownloadAll1`
2) Download New Transmissions - `ctl00$ContentPlaceHolder1$DownloadAll2`
3) Download All Data - `ctl00$ContentPlaceHolder1$DownloadAll3`
4) Download Download All Transmissions - `ctl00$ContentPlaceHolder1$DownloadAll4`
5) Download All Events - `ctl00$ContentPlaceHolder1$DownLoadlastEvents`


***

#### CSV Legacy/Loose Files

Sometimes we just have a bunch of loose csv files from old collars or maybe we received them by email regardless of how we got them we want to use them. The function `fetch_csv` is a wrapper for just this task. One *special* and undesirable feature of some collar data is that it has a header of many lines containing metadata of some sort. Some examples are contained in this package. You can run `system.file("extdata", "telonics.csv", package = "collar")` to see a nice example of an extra large header that makes life difficult.

A clean first example uses a file without a problematic header
```{r}
lotek_fpath <- system.file(
  "extdata",
  "lotek.csv",
  package = "collar",
  mustWork = TRUE
)

lotek <- fetch_csv(lotek_fpath)
```

The function fetch_csv allows us to read multiple csv's, but for the moment we left that to the user. For example, if we wanted to read all the csv files stored in this package we could write the following.
```{r eval = F}
fpaths <- list.files(dirname(lotek_fpath), full.names = T, pattern = "csv$")

my_dat <- purrr::map(fpaths, fetch_csv)
```

If you ran the code above you would see that the object returned by the function is not very useable. The point of keeping this code in is to demonstrate the need for consistency and a simple way to loop over many file names. All of the files being read should have a similar format and then skipping lines of the header (as you will see shortly) and other data handling techniques can be successful. If you are going to read multiple files they should have the same column names, number of columns and the names should mean the same thing.

A nicer example is reading the two Lotek files that we have saved for you
```{r}
lotek_fpaths <- c(lotek_fpath, lotek_fpath)

lotek_dat <- purrr::map_df(lotek_fpaths, fetch_csv)

```

What if your file has a large header like the Telonics file referenced earlier? Well, we built a function to guess at the number of rows to omit when reading files with headers. Let's try it with the Telonics file provided with this package.

```{r}
telonics_fpath <- system.file(
  "extdata",
  "telonics.csv",
  package = "collar",
  mustWork = TRUE
)

tel_dat <- fetch_csv(telonics_fpath)
```

That was ugly, but we have the `cllr_remove_header` to help with this situation. In order to use the function we just need to know one column name. For example, if you open the csv and look at it we see that one column name is "GPS Latitude". Now let's remove the header from our data.

```{r}
clean_tel <- cllr_remove_header(tel_dat, "GPS Latitude", TRUE)
```

Now our data no longer have the large header with all the metadata. At this point we may wish to add a unique identifier for each animal.

```{r}
id_tel <- cllr_add_id(clean_tel, "Dave")
```

Cool, but how is that useful if I have to do it for each animal? Well, we can automate the reading and morphing just like before using purrr.

```{r}

```

